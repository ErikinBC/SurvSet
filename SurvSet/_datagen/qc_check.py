"""
Final check on the output files generated by the SurvSet data generation pipeline.

# Call the module manually with the defaults from the command line
>>> python3 -m SurvSet._datagen.qc_check
"""

def qc_check(
        min_num: int,
        ) -> None:
    # Load external modules
    import os
    import numpy as np
    import pandas as pd
    import plotnine as pn
    from mizani.formatters import custom_format
    # Load internal modules
    from ..utils import di_ref, fn_df_ds
    from . import dir_pickles, dir_figures
    from .utils.funs_support import str_detect, str_subset

    # Find the reference datasets
    fn_output = pd.Series(os.listdir(dir_pickles))
    fn_output = fn_output[~fn_output.eq(fn_df_ds)]
    is_pickle = str_detect(fn_output, 'pickle$')
    assert is_pickle.all(), 'An unexpected file detected in output: %s' % list(fn_output[~is_pickle])

    # Set up the path
    path_df_ds = os.path.join(dir_pickles, fn_df_ds)


    ################################
    # --- (1) LOOP THROUGH ALL --- #

    holder = []
    for i, fn in enumerate(fn_output):
        ds = fn.replace('.pickle','')
        # print('--- %s (%i of %i) ---' % (ds, i+1, n_output))
        path_fn = os.path.join(dir_pickles, fn)
        df = pd.read_pickle(path_fn, )
        n = len(df)
        cn_fac = str_subset(df.columns, '^fac\\_')
        cn_num = str_subset(df.columns, '^num\\_')
        n_fac = len(cn_fac)
        n_num = len(cn_num)
        # (i) Check data-types
        num_dt = df[cn_num].dtypes
        assert ((num_dt == float) | (num_dt == int)).all(), 'expected all numeric variables to be either floats or ints'
        assert df[cn_fac].dtypes.eq('category').all(), 'expected all factor variables to be categories'
        # (ii) time is positive
        assert np.all(df['time'] >= 0), 'time is not positive!'
        # (iii) Factors should have no missing
        n_ohe = 0
        if n_fac > 0:
            assert df[cn_fac].notnull().any().all(), 'A factor has a missing value!'
            dat_fac = df[cn_fac].apply(lambda x: x.unique().shape[0])
            dat_fac = dat_fac.reset_index().rename(columns={0:'n'}).assign(ds=ds)
            n_ohe = np.sum(dat_fac['n']-1)            
        # (iv) Numberics have a minimum of Z categories
        if n_num > 0:
            dat_num = df[cn_num].apply(lambda x: x.unique().shape[0])
            dat_num = dat_num.reset_index().rename(columns={0:'n'}).assign(ds=ds)
            assert np.all(dat_num['n'] >= min_num), 'Numeric must have at least %i unique values!' % min_num   
        # (v) Time dependent checks
        is_td = ('time2' in df.columns)
        if is_td:
            assert np.all(df['time2'] > df['time']), 'time2 is not greater than time!'
            assert df['pid'].duplicated().any(), 'At least one pid must be duplicated!'
        # (vi) funs_ref matches each
        assert ds in di_ref, '%s not found in refence!!' % ds
        # (vii) store information
        res = pd.DataFrame({'ds':ds, 'is_td':is_td, 'n':n, 'n_fac':n_fac, 'n_ohe':n_ohe, 'n_num':n_num}, index=[i])
        holder.append(res)
    # Merge and save
    df_ds = pd.concat(holder)
    df_ds.to_csv(path_df_ds, index=False)


    ###############################
    # --- (2) FIGURES & STATS --- #

    # Dimensionality by dataset
    df_ds = df_ds.assign(p=lambda x: x['n_ohe']+x['n_num'])
    df_ds = df_ds.assign(n_data=lambda x: x['p']*x['n'])
    ds_ord = df_ds.sort_values('n_data')['ds'].values
    df_ds['ds'] = pd.Categorical(df_ds['ds'], ds_ord)
    ds_long = df_ds.melt(['ds','is_td'],['p','n'],'axis','val')

    # Plot
    format_int = custom_format(fmt='%i', style='old')
    gg_ds = (pn.ggplot(ds_long, pn.aes(y='ds',x='val',color='axis',shape='is_td')) + 
        pn.theme_bw() + pn.labs(x='Dataset size') + 
        pn.geom_point() + pn.scale_x_log10(labels=format_int) + 
        pn.theme(axis_title_y=pn.element_blank()) + 
        pn.scale_color_discrete(name='Axis',labels=['Rows','Columns']) + 
        pn.scale_shape_discrete(name='Time-varying'))
    gg_ds.save(os.path.join(dir_figures,'gg_ds.png'),height=10, width=6)

    print('~~~ End of qc_check.py ~~~')


if __name__ == '__main__':
    from . import di_argpase_defaults
    # Ensure all output files follow QC standards
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--min_num', type=int, help=di_argpase_defaults['min_num']['help'], default=di_argpase_defaults['min_num']['val'])
    args = parser.parse_args()
    min_num = args.min_num

    # Call the main function
    qc_check(
        min_num=args.min_num,
    )
